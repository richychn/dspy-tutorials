{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc27e70d-0193-4bf3-b2f6-7cd0641b430b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.teleprompt import BootstrapFewShot, BootstrapFewShotWithRandomSearch, BootstrapFinetune\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ae4b6-5199-4aea-9496-c607280afeeb",
   "metadata": {},
   "source": [
    "## Set up models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abbcec13-1fc4-48a9-8bbc-92ba493530bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo = dspy.OpenAI(model='gpt-3.5-turbo-instruct')\n",
    "colbertv2 = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "\n",
    "dspy.settings.configure(rm=colbertv2, lm=turbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11081e-b886-465c-bba3-d55b3ae8535d",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8236195-6f71-481d-8b22-05affc6b914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [('Who was the director of the 2009 movie featuring Peter Outerbridge as William Easton?', 'Kevin Greutert'),\n",
    "         ('The heir to the Du Pont family fortune sponsored what wrestling team?', 'Foxcatcher'),\n",
    "         ('In what year was the star of To Hell and Back born?', '1925'),\n",
    "         ('Which award did the first book of Gary Zukav receive?', 'U.S. National Book Award'),\n",
    "         ('What documentary about the Gilgo Beach Killer debuted on A&E?', 'The Killing Season'),\n",
    "         ('Which author is English: John Braine or Studs Terkel?', 'John Braine'),\n",
    "         ('Who produced the album that included a re-recording of \"Lithium\"?', 'Butch Vig')]\n",
    "\n",
    "train = [dspy.Example(question=question, answer=answer).with_inputs('question') for question, answer in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bc15e0f-7fe6-403a-ac58-c88da6d58def",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = [('Who has a broader scope of profession: E. L. Doctorow or Julia Peterkin?', 'E. L. Doctorow'),\n",
    "       ('Right Back At It Again contains lyrics co-written by the singer born in what city?', 'Gainesville, Florida'),\n",
    "       ('What year was the party of the winner of the 1971 San Francisco mayoral election founded?', '1828'),\n",
    "       ('Anthony Dirrell is the brother of which super middleweight title holder?', 'Andre Dirrell'),\n",
    "       ('The sports nutrition business established by Oliver Cookson is based in which county in the UK?', 'Cheshire'),\n",
    "       ('Find the birth date of the actor who played roles in First Wives Club and Searching for the Elephant.', 'February 13, 1980'),\n",
    "       ('Kyle Moran was born in the town on what river?', 'Castletown River'),\n",
    "       (\"The actress who played the niece in the Priest film was born in what city, country?\", 'Surrey, England'),\n",
    "       ('Name the movie in which the daughter of Noel Harrison plays Violet Trefusis.', 'Portrait of a Marriage'),\n",
    "       ('What year was the father of the Princes in the Tower born?', '1442'),\n",
    "       ('What river is near the Crichton Collegiate Church?', 'the River Tyne'),\n",
    "       ('Who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000?', 'Renault'),\n",
    "       ('André Zucca was a French photographer who worked with a German propaganda magazine published by what Nazi organization?', 'the Wehrmacht')]\n",
    "\n",
    "dev = [dspy.Example(question=question, answer=answer).with_inputs('question') for question, answer in dev]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148120ae-8f1e-4f9b-9ed8-5b62373808d3",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6436cad9-2b55-4305-817b-d5043095713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_THREADS = 32\n",
    "evaluate_hotpot = Evaluate(devset=dev, metric=metric_EM, num_threads=NUM_THREADS, display_progress=True, display_table=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8262d2a-ebc4-466e-9557-ab82a8d4e701",
   "metadata": {},
   "source": [
    "# Chain of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "455865a4-0061-4c97-b01d-f25ede5d0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoT(dspy.Module):  # let's define a new module\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # here we declare the chain of thought sub-module, so we can later compile it (e.g., teach it a prompt)\n",
    "        self.generate_answer = dspy.ChainOfThought('question -> answer')\n",
    "    \n",
    "    def forward(self, question):\n",
    "        return self.generate_answer(question=question)  # here we use the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eb399e2-7e3e-4978-98c7-f5e5fc67e094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████████████████████▏                                                                                                      | 2/7 [00:02<00:05,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metric_EM = dspy.evaluate.answer_exact_match\n",
    "\n",
    "optimizer = BootstrapFewShot(metric=metric_EM, max_bootstrapped_demos=2)\n",
    "cot_compiled = optimizer.compile(CoT(), trainset=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93d5a3f3-e306-43c8-a16e-d68a7fc509bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who produced the album that included a re-recording of \"Lithium\"?\n",
      "Answer: Butch Vig\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which award did the first book of Gary Zukav receive?\n",
      "Answer: U.S. National Book Award\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which author is English: John Braine or Studs Terkel?\n",
      "Answer: John Braine\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who was the director of the 2009 movie featuring Peter Outerbridge as William Easton?\n",
      "Answer: Kevin Greutert\n",
      "\n",
      "---\n",
      "\n",
      "Question: In what year was the star of To Hell and Back born?\n",
      "Answer: 1925\n",
      "\n",
      "---\n",
      "\n",
      "Question: What documentary about the Gilgo Beach Killer debuted on A&E?\n",
      "Answer: The Killing Season\n",
      "\n",
      "---\n",
      "\n",
      "Question: The heir to the Du Pont family fortune sponsored what wrestling team?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m find the answer. We know that the Du Pont family fortune is one of the largest fortunes in the United States. We also know that the heir to the Du Pont family fortune is a wrestling enthusiast. Therefore, the heir to the Du Pont family fortune would likely sponsor a wrestling team.\n",
      "Answer: Foxcatcher\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "turbo.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f041523e-5b40-427e-82fa-0264be2bb3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 13  (23.1): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:01<00:00,  8.45it/s]\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:263: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['✔️ [True]' 'False' 'False' '✔️ [True]' '✔️ [True]' 'False' 'False'\n",
      " 'False' 'False' 'False' 'False' 'False' 'False']' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 13  (23.1%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3034e th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3034e td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3034e_row0_col0, #T_3034e_row0_col1, #T_3034e_row0_col2, #T_3034e_row0_col3, #T_3034e_row0_col4, #T_3034e_row1_col0, #T_3034e_row1_col1, #T_3034e_row1_col2, #T_3034e_row1_col3, #T_3034e_row1_col4, #T_3034e_row2_col0, #T_3034e_row2_col1, #T_3034e_row2_col2, #T_3034e_row2_col3, #T_3034e_row2_col4, #T_3034e_row3_col0, #T_3034e_row3_col1, #T_3034e_row3_col2, #T_3034e_row3_col3, #T_3034e_row3_col4, #T_3034e_row4_col0, #T_3034e_row4_col1, #T_3034e_row4_col2, #T_3034e_row4_col3, #T_3034e_row4_col4, #T_3034e_row5_col0, #T_3034e_row5_col1, #T_3034e_row5_col2, #T_3034e_row5_col3, #T_3034e_row5_col4, #T_3034e_row6_col0, #T_3034e_row6_col1, #T_3034e_row6_col2, #T_3034e_row6_col3, #T_3034e_row6_col4, #T_3034e_row7_col0, #T_3034e_row7_col1, #T_3034e_row7_col2, #T_3034e_row7_col3, #T_3034e_row7_col4, #T_3034e_row8_col0, #T_3034e_row8_col1, #T_3034e_row8_col2, #T_3034e_row8_col3, #T_3034e_row8_col4, #T_3034e_row9_col0, #T_3034e_row9_col1, #T_3034e_row9_col2, #T_3034e_row9_col3, #T_3034e_row9_col4, #T_3034e_row10_col0, #T_3034e_row10_col1, #T_3034e_row10_col2, #T_3034e_row10_col3, #T_3034e_row10_col4, #T_3034e_row11_col0, #T_3034e_row11_col1, #T_3034e_row11_col2, #T_3034e_row11_col3, #T_3034e_row11_col4, #T_3034e_row12_col0, #T_3034e_row12_col1, #T_3034e_row12_col2, #T_3034e_row12_col3, #T_3034e_row12_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3034e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3034e_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_3034e_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_3034e_level0_col2\" class=\"col_heading level0 col2\" >rationale</th>\n",
       "      <th id=\"T_3034e_level0_col3\" class=\"col_heading level0 col3\" >pred_answer</th>\n",
       "      <th id=\"T_3034e_level0_col4\" class=\"col_heading level0 col4\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3034e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3034e_row0_col0\" class=\"data row0 col0\" >Who has a broader scope of profession: E. L. Doctorow or Julia Peterkin?</td>\n",
       "      <td id=\"T_3034e_row0_col1\" class=\"data row0 col1\" >E. L. Doctorow</td>\n",
       "      <td id=\"T_3034e_row0_col2\" class=\"data row0 col2\" >find the answer. We know that E. L. Doctorow is a novelist, editor, and professor, while Julia Peterkin is a novelist and short story writer....</td>\n",
       "      <td id=\"T_3034e_row0_col3\" class=\"data row0 col3\" >E. L. Doctorow</td>\n",
       "      <td id=\"T_3034e_row0_col4\" class=\"data row0 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3034e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3034e_row1_col0\" class=\"data row1 col0\" >Right Back At It Again contains lyrics co-written by the singer born in what city?</td>\n",
       "      <td id=\"T_3034e_row1_col1\" class=\"data row1 col1\" >Gainesville, Florida</td>\n",
       "      <td id=\"T_3034e_row1_col2\" class=\"data row1 col2\" >find the answer. We know that the song \"Right Back At It Again\" was released in 2013, so we can look up the songs that...</td>\n",
       "      <td id=\"T_3034e_row1_col3\" class=\"data row1 col3\" >Ocala, Florida</td>\n",
       "      <td id=\"T_3034e_row1_col4\" class=\"data row1 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3034e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3034e_row2_col0\" class=\"data row2 col0\" >What year was the party of the winner of the 1971 San Francisco mayoral election founded?</td>\n",
       "      <td id=\"T_3034e_row2_col1\" class=\"data row2 col1\" >1828</td>\n",
       "      <td id=\"T_3034e_row2_col2\" class=\"data row2 col2\" >find the answer. We know that the 1971 San Francisco mayoral election was held in 1971. We can then look up the winner of that...</td>\n",
       "      <td id=\"T_3034e_row2_col3\" class=\"data row2 col3\" >1969</td>\n",
       "      <td id=\"T_3034e_row2_col4\" class=\"data row2 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3034e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3034e_row3_col0\" class=\"data row3 col0\" >Anthony Dirrell is the brother of which super middleweight title holder?</td>\n",
       "      <td id=\"T_3034e_row3_col1\" class=\"data row3 col1\" >Andre Dirrell</td>\n",
       "      <td id=\"T_3034e_row3_col2\" class=\"data row3 col2\" >find the answer. We know that Anthony Dirrell is a professional boxer, and specifically a super middleweight. We can then look up the current super...</td>\n",
       "      <td id=\"T_3034e_row3_col3\" class=\"data row3 col3\" >Andre Dirrell</td>\n",
       "      <td id=\"T_3034e_row3_col4\" class=\"data row3 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3034e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3034e_row4_col0\" class=\"data row4 col0\" >The sports nutrition business established by Oliver Cookson is based in which county in the UK?</td>\n",
       "      <td id=\"T_3034e_row4_col1\" class=\"data row4 col1\" >Cheshire</td>\n",
       "      <td id=\"T_3034e_row4_col2\" class=\"data row4 col2\" >find the answer. We know that Oliver Cookson is the founder of a sports nutrition business. We can then look up the location of the...</td>\n",
       "      <td id=\"T_3034e_row4_col3\" class=\"data row4 col3\" >Cheshire</td>\n",
       "      <td id=\"T_3034e_row4_col4\" class=\"data row4 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3034e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3034e_row5_col0\" class=\"data row5 col0\" >Find the birth date of the actor who played roles in First Wives Club and Searching for the Elephant.</td>\n",
       "      <td id=\"T_3034e_row5_col1\" class=\"data row5 col1\" >February 13, 1980</td>\n",
       "      <td id=\"T_3034e_row5_col2\" class=\"data row5 col2\" >find the answer. We know that the actor played roles in both First Wives Club and Searching for the Elephant. We can then look up...</td>\n",
       "      <td id=\"T_3034e_row5_col3\" class=\"data row5 col3\" >September 18, 1961</td>\n",
       "      <td id=\"T_3034e_row5_col4\" class=\"data row5 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3034e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3034e_row6_col0\" class=\"data row6 col0\" >Kyle Moran was born in the town on what river?</td>\n",
       "      <td id=\"T_3034e_row6_col1\" class=\"data row6 col1\" >Castletown River</td>\n",
       "      <td id=\"T_3034e_row6_col2\" class=\"data row6 col2\" >find the answer. We know that Kyle Moran was born in a town, so we can look up the towns that he could have been...</td>\n",
       "      <td id=\"T_3034e_row6_col3\" class=\"data row6 col3\" >Hudson River</td>\n",
       "      <td id=\"T_3034e_row6_col4\" class=\"data row6 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3034e_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3034e_row7_col0\" class=\"data row7 col0\" >The actress who played the niece in the Priest film was born in what city, country?</td>\n",
       "      <td id=\"T_3034e_row7_col1\" class=\"data row7 col1\" >Surrey, England</td>\n",
       "      <td id=\"T_3034e_row7_col2\" class=\"data row7 col2\" >find the answer. We know that the actress who played the niece in the Priest film is a well-known actress, so we can look up...</td>\n",
       "      <td id=\"T_3034e_row7_col3\" class=\"data row7 col3\" >London, England</td>\n",
       "      <td id=\"T_3034e_row7_col4\" class=\"data row7 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3034e_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_3034e_row8_col0\" class=\"data row8 col0\" >Name the movie in which the daughter of Noel Harrison plays Violet Trefusis.</td>\n",
       "      <td id=\"T_3034e_row8_col1\" class=\"data row8 col1\" >Portrait of a Marriage</td>\n",
       "      <td id=\"T_3034e_row8_col2\" class=\"data row8 col2\" >find the answer. We know that Noel Harrison is an actor, and that he has a daughter. We can then look up the movies that...</td>\n",
       "      <td id=\"T_3034e_row8_col3\" class=\"data row8 col3\" >The Trials of Oscar Wilde</td>\n",
       "      <td id=\"T_3034e_row8_col4\" class=\"data row8 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3034e_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_3034e_row9_col0\" class=\"data row9 col0\" >What year was the father of the Princes in the Tower born?</td>\n",
       "      <td id=\"T_3034e_row9_col1\" class=\"data row9 col1\" >1442</td>\n",
       "      <td id=\"T_3034e_row9_col2\" class=\"data row9 col2\" >find the answer. We know that the Princes in the Tower were born in 1470 and 1473, and their father was born when he was...</td>\n",
       "      <td id=\"T_3034e_row9_col3\" class=\"data row9 col3\" >1457</td>\n",
       "      <td id=\"T_3034e_row9_col4\" class=\"data row9 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3034e_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_3034e_row10_col0\" class=\"data row10 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
       "      <td id=\"T_3034e_row10_col1\" class=\"data row10 col1\" >the River Tyne</td>\n",
       "      <td id=\"T_3034e_row10_col2\" class=\"data row10 col2\" >find the answer. We know that the Crichton Collegiate Church is located in Scotland. We can then look up the rivers in Scotland and find...</td>\n",
       "      <td id=\"T_3034e_row10_col3\" class=\"data row10 col3\" >River Nith</td>\n",
       "      <td id=\"T_3034e_row10_col4\" class=\"data row10 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3034e_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_3034e_row11_col0\" class=\"data row11 col0\" >Who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000?</td>\n",
       "      <td id=\"T_3034e_row11_col1\" class=\"data row11 col1\" >Renault</td>\n",
       "      <td id=\"T_3034e_row11_col2\" class=\"data row11 col2\" >find the answer. We know that Michael Schumacher raced for the team in the 1995 Monaco Grand Prix. We also know that the team was...</td>\n",
       "      <td id=\"T_3034e_row11_col3\" class=\"data row11 col3\" >Eddie Jordan</td>\n",
       "      <td id=\"T_3034e_row11_col4\" class=\"data row11 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3034e_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_3034e_row12_col0\" class=\"data row12 col0\" >André Zucca was a French photographer who worked with a German propaganda magazine published by what Nazi organization?</td>\n",
       "      <td id=\"T_3034e_row12_col1\" class=\"data row12 col1\" >the Wehrmacht</td>\n",
       "      <td id=\"T_3034e_row12_col2\" class=\"data row12 col2\" >find the answer. We know that André Zucca was a French photographer, so we can look up French photographers during the time of Nazi Germany....</td>\n",
       "      <td id=\"T_3034e_row12_col3\" class=\"data row12 col3\" >Schutzstaffel (SS)</td>\n",
       "      <td id=\"T_3034e_row12_col4\" class=\"data row12 col4\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x130dcf010>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "23.08"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_hotpot(cot_compiled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca23e63b-08e4-4fb0-b389-287678f7e11b",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeac2d5e-fb9e-40dd-95fd-acf590bd533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # declare three modules: the retriever, a query generator, and an answer generator\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_query = dspy.ChainOfThought(\"question -> search_query\")\n",
    "        self.generate_answer = dspy.ChainOfThought(\"context, question -> answer\")\n",
    "    \n",
    "    def forward(self, question):\n",
    "        # generate a search query from the question, and use it to retrieve passages\n",
    "        search_query = self.generate_query(question=question).search_query\n",
    "        passages = self.retrieve(search_query).passages\n",
    "\n",
    "        # generate an answer from the passages and the question\n",
    "        return self.generate_answer(context=passages, question=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da276998-96b8-4b68-8c2e-0b33ed06c778",
   "metadata": {},
   "source": [
    "Out of curiosity, evluate the uncompiled or zero-shot version of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d53b98f-4b40-4380-ac47-91a60cb70847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 13  (15.4): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:03<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 13  (15.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.38"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_hotpot(RAG(), display_table=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f57945ce-ddd0-4e62-b7c0-44505b3002f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 2 traces per predictor.\n",
      "Will attempt to train 8 candidate sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 13  (15.4): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 2270.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 13  (15.4%)\n",
      "Score: 15.38 for set: [0, 0]\n",
      "New best score: 15.38 for seed -3\n",
      "Scores so far: [15.38]\n",
      "Best score: 15.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 13  (38.5): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:01<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 13  (38.5%)\n",
      "Score: 38.46 for set: [7, 7]\n",
      "New best score: 38.46 for seed -2\n",
      "Scores so far: [15.38, 38.46]\n",
      "Best score: 38.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████████████████████▏                                                                                                      | 2/7 [00:04<00:11,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 13  (30.8): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:03<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 13  (30.8%)\n",
      "Score: 30.77 for set: [7, 7]\n",
      "Scores so far: [15.38, 38.46, 30.77]\n",
      "Best score: 38.46\n",
      "Average of max per entry across top 1 scores: 0.38461538461538464\n",
      "Average of max per entry across top 2 scores: 0.46153846153846156\n",
      "Average of max per entry across top 3 scores: 0.6153846153846154\n",
      "Average of max per entry across top 5 scores: 0.6153846153846154\n",
      "Average of max per entry across top 8 scores: 0.6153846153846154\n",
      "Average of max per entry across top 9999 scores: 0.6153846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████████████████████████████████████▎                                                             | 4/7 [00:06<00:04,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 13  (30.8): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:03<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 13  (30.8%)\n",
      "Score: 30.77 for set: [7, 7]\n",
      "Scores so far: [15.38, 38.46, 30.77, 30.77]\n",
      "Best score: 38.46\n",
      "Average of max per entry across top 1 scores: 0.38461538461538464\n",
      "Average of max per entry across top 2 scores: 0.46153846153846156\n",
      "Average of max per entry across top 3 scores: 0.6153846153846154\n",
      "Average of max per entry across top 5 scores: 0.6923076923076923\n",
      "Average of max per entry across top 8 scores: 0.6923076923076923\n",
      "Average of max per entry across top 9999 scores: 0.6923076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████▌                                                                                                                           | 1/7 [00:01<00:11,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 13  (30.8): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:03<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 13  (30.8%)\n",
      "Score: 30.77 for set: [7, 7]\n",
      "Scores so far: [15.38, 38.46, 30.77, 30.77, 30.77]\n",
      "Best score: 38.46\n",
      "Average of max per entry across top 1 scores: 0.38461538461538464\n",
      "Average of max per entry across top 2 scores: 0.46153846153846156\n",
      "Average of max per entry across top 3 scores: 0.6153846153846154\n",
      "Average of max per entry across top 5 scores: 0.7692307692307693\n",
      "Average of max per entry across top 8 scores: 0.7692307692307693\n",
      "Average of max per entry across top 9999 scores: 0.7692307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████████████████████▏                                                                                                      | 2/7 [00:02<00:05,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 13  (38.5): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:01<00:00,  9.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 13  (38.5%)\n",
      "Score: 38.46 for set: [7, 7]\n",
      "Scores so far: [15.38, 38.46, 30.77, 30.77, 30.77, 38.46]\n",
      "Best score: 38.46\n",
      "Average of max per entry across top 1 scores: 0.38461538461538464\n",
      "Average of max per entry across top 2 scores: 0.6153846153846154\n",
      "Average of max per entry across top 3 scores: 0.6153846153846154\n",
      "Average of max per entry across top 5 scores: 0.7692307692307693\n",
      "Average of max per entry across top 8 scores: 0.7692307692307693\n",
      "Average of max per entry across top 9999 scores: 0.7692307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████▌                                                                                                                           | 1/7 [00:00<00:05,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 13  (23.1): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:03<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 13  (23.1%)\n",
      "Score: 23.08 for set: [7, 7]\n",
      "Scores so far: [15.38, 38.46, 30.77, 30.77, 30.77, 38.46, 23.08]\n",
      "Best score: 38.46\n",
      "Average of max per entry across top 1 scores: 0.38461538461538464\n",
      "Average of max per entry across top 2 scores: 0.6153846153846154\n",
      "Average of max per entry across top 3 scores: 0.6153846153846154\n",
      "Average of max per entry across top 5 scores: 0.7692307692307693\n",
      "Average of max per entry across top 8 scores: 0.8461538461538461\n",
      "Average of max per entry across top 9999 scores: 0.8461538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████▌                                                                                                                           | 1/7 [00:01<00:10,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 13  (30.8): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:02<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 13  (30.8%)\n",
      "Score: 30.77 for set: [7, 7]\n",
      "Scores so far: [15.38, 38.46, 30.77, 30.77, 30.77, 38.46, 23.08, 30.77]\n",
      "Best score: 38.46\n",
      "Average of max per entry across top 1 scores: 0.38461538461538464\n",
      "Average of max per entry across top 2 scores: 0.6153846153846154\n",
      "Average of max per entry across top 3 scores: 0.6153846153846154\n",
      "Average of max per entry across top 5 scores: 0.7692307692307693\n",
      "Average of max per entry across top 8 scores: 0.8461538461538461\n",
      "Average of max per entry across top 9999 scores: 0.8461538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████████████████████████▋                                                                                  | 3/7 [00:05<00:07,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 9  (33.3):  69%|█████████████████████████████████████████████████████████████████████████████▌                                  | 9/13 [00:02<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 13  (30.8): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:06<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 13  (30.8%)\n",
      "Score: 30.77 for set: [7, 7]\n",
      "Scores so far: [15.38, 38.46, 30.77, 30.77, 30.77, 38.46, 23.08, 30.77, 30.77]\n",
      "Best score: 38.46\n",
      "Average of max per entry across top 1 scores: 0.38461538461538464\n",
      "Average of max per entry across top 2 scores: 0.6153846153846154\n",
      "Average of max per entry across top 3 scores: 0.6153846153846154\n",
      "Average of max per entry across top 5 scores: 0.7692307692307693\n",
      "Average of max per entry across top 8 scores: 0.8461538461538461\n",
      "Average of max per entry across top 9999 scores: 0.8461538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████████████████████▏                                                                                                      | 2/7 [00:01<00:04,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 3  (66.7):  23%|█████████████████████████▊                                                                                      | 3/13 [00:01<00:03,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 5  (40.0):  38%|███████████████████████████████████████████                                                                     | 5/13 [00:02<00:03,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 6  (33.3):  46%|███████████████████████████████████████████████████▋                                                            | 6/13 [00:02<00:03,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 9  (55.6):  69%|█████████████████████████████████████████████████████████████████████████████▌                                  | 9/13 [00:04<00:02,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 13  (38.5): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:09<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 13  (38.5%)\n",
      "Score: 38.46 for set: [7, 7]\n",
      "Scores so far: [15.38, 38.46, 30.77, 30.77, 30.77, 38.46, 23.08, 30.77, 30.77, 38.46]\n",
      "Best score: 38.46\n",
      "Average of max per entry across top 1 scores: 0.38461538461538464\n",
      "Average of max per entry across top 2 scores: 0.6153846153846154\n",
      "Average of max per entry across top 3 scores: 0.7692307692307693\n",
      "Average of max per entry across top 5 scores: 0.8461538461538461\n",
      "Average of max per entry across top 8 scores: 0.9230769230769231\n",
      "Average of max per entry across top 9999 scores: 0.9230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████████████████████████████████████▎                                                             | 4/7 [00:04<00:03,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 5  (20.0):  38%|███████████████████████████████████████████                                                                     | 5/13 [00:03<00:04,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 7  (28.6):  54%|████████████████████████████████████████████████████████████▎                                                   | 7/13 [00:04<00:04,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 8  (37.5):  62%|████████████████████████████████████████████████████████████████████▉                                           | 8/13 [00:05<00:04,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 10  (30.0):  77%|████████████████████████████████████████████████████████████████████████████████████▌                         | 10/13 [00:07<00:02,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 13  (30.8): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:12<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 13  (30.8%)\n",
      "Score: 30.77 for set: [7, 7]\n",
      "Scores so far: [15.38, 38.46, 30.77, 30.77, 30.77, 38.46, 23.08, 30.77, 30.77, 38.46, 30.77]\n",
      "Best score: 38.46\n",
      "Average of max per entry across top 1 scores: 0.38461538461538464\n",
      "Average of max per entry across top 2 scores: 0.6153846153846154\n",
      "Average of max per entry across top 3 scores: 0.7692307692307693\n",
      "Average of max per entry across top 5 scores: 0.8461538461538461\n",
      "Average of max per entry across top 8 scores: 0.9230769230769231\n",
      "Average of max per entry across top 9999 scores: 1.0\n",
      "11 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer2 = BootstrapFewShotWithRandomSearch(metric=metric_EM, max_bootstrapped_demos=2, num_candidate_programs=8, num_threads=NUM_THREADS)\n",
    "rag_compiled = optimizer2.compile(RAG(), trainset=train, valset=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e60087bf-5bda-484a-bd5e-22f9590163e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 13  (38.5): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 1486.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 13  (38.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:263: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['✔️ [True]' 'False' 'False' '✔️ [True]' '✔️ [True]' 'False' 'False'\n",
      " 'False' 'False' 'False' '✔️ [True]' '✔️ [True]' 'False']' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_66140 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_66140 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_66140_row0_col0, #T_66140_row0_col1, #T_66140_row0_col2, #T_66140_row0_col3, #T_66140_row0_col4, #T_66140_row1_col0, #T_66140_row1_col1, #T_66140_row1_col2, #T_66140_row1_col3, #T_66140_row1_col4, #T_66140_row2_col0, #T_66140_row2_col1, #T_66140_row2_col2, #T_66140_row2_col3, #T_66140_row2_col4, #T_66140_row3_col0, #T_66140_row3_col1, #T_66140_row3_col2, #T_66140_row3_col3, #T_66140_row3_col4, #T_66140_row4_col0, #T_66140_row4_col1, #T_66140_row4_col2, #T_66140_row4_col3, #T_66140_row4_col4, #T_66140_row5_col0, #T_66140_row5_col1, #T_66140_row5_col2, #T_66140_row5_col3, #T_66140_row5_col4, #T_66140_row6_col0, #T_66140_row6_col1, #T_66140_row6_col2, #T_66140_row6_col3, #T_66140_row6_col4, #T_66140_row7_col0, #T_66140_row7_col1, #T_66140_row7_col2, #T_66140_row7_col3, #T_66140_row7_col4, #T_66140_row8_col0, #T_66140_row8_col1, #T_66140_row8_col2, #T_66140_row8_col3, #T_66140_row8_col4, #T_66140_row9_col0, #T_66140_row9_col1, #T_66140_row9_col2, #T_66140_row9_col3, #T_66140_row9_col4, #T_66140_row10_col0, #T_66140_row10_col1, #T_66140_row10_col2, #T_66140_row10_col3, #T_66140_row10_col4, #T_66140_row11_col0, #T_66140_row11_col1, #T_66140_row11_col2, #T_66140_row11_col3, #T_66140_row11_col4, #T_66140_row12_col0, #T_66140_row12_col1, #T_66140_row12_col2, #T_66140_row12_col3, #T_66140_row12_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_66140\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_66140_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_66140_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_66140_level0_col2\" class=\"col_heading level0 col2\" >rationale</th>\n",
       "      <th id=\"T_66140_level0_col3\" class=\"col_heading level0 col3\" >pred_answer</th>\n",
       "      <th id=\"T_66140_level0_col4\" class=\"col_heading level0 col4\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_66140_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_66140_row0_col0\" class=\"data row0 col0\" >Who has a broader scope of profession: E. L. Doctorow or Julia Peterkin?</td>\n",
       "      <td id=\"T_66140_row0_col1\" class=\"data row0 col1\" >E. L. Doctorow</td>\n",
       "      <td id=\"T_66140_row0_col2\" class=\"data row0 col2\" >determine who has a broader scope of profession. We know that E. L. Doctorow was an American novelist, editor, and professor, while Julia Peterkin was...</td>\n",
       "      <td id=\"T_66140_row0_col3\" class=\"data row0 col3\" >E. L. Doctorow</td>\n",
       "      <td id=\"T_66140_row0_col4\" class=\"data row0 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66140_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_66140_row1_col0\" class=\"data row1 col0\" >Right Back At It Again contains lyrics co-written by the singer born in what city?</td>\n",
       "      <td id=\"T_66140_row1_col1\" class=\"data row1 col1\" >Gainesville, Florida</td>\n",
       "      <td id=\"T_66140_row1_col2\" class=\"data row1 col2\" >produce the answer. We know that the song \"Right Back At It Again\" is from the album \"Common Courtesy\" by A Day to Remember. We...</td>\n",
       "      <td id=\"T_66140_row1_col3\" class=\"data row1 col3\" >The singer was born in Ocala, Florida.</td>\n",
       "      <td id=\"T_66140_row1_col4\" class=\"data row1 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66140_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_66140_row2_col0\" class=\"data row2 col0\" >What year was the party of the winner of the 1971 San Francisco mayoral election founded?</td>\n",
       "      <td id=\"T_66140_row2_col1\" class=\"data row2 col1\" >1828</td>\n",
       "      <td id=\"T_66140_row2_col2\" class=\"data row2 col2\" >find the year the party of the winner of the 1971 San Francisco mayoral election was founded. We know that the winner of the election...</td>\n",
       "      <td id=\"T_66140_row2_col3\" class=\"data row2 col3\" >1849</td>\n",
       "      <td id=\"T_66140_row2_col4\" class=\"data row2 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66140_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_66140_row3_col0\" class=\"data row3 col0\" >Anthony Dirrell is the brother of which super middleweight title holder?</td>\n",
       "      <td id=\"T_66140_row3_col1\" class=\"data row3 col1\" >Andre Dirrell</td>\n",
       "      <td id=\"T_66140_row3_col2\" class=\"data row3 col2\" >produce the answer. We know that Anthony Dirrell is a professional boxer and the younger brother of Andre Dirrell, who is also a professional boxer....</td>\n",
       "      <td id=\"T_66140_row3_col3\" class=\"data row3 col3\" >Andre Dirrell</td>\n",
       "      <td id=\"T_66140_row3_col4\" class=\"data row3 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66140_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_66140_row4_col0\" class=\"data row4 col0\" >The sports nutrition business established by Oliver Cookson is based in which county in the UK?</td>\n",
       "      <td id=\"T_66140_row4_col1\" class=\"data row4 col1\" >Cheshire</td>\n",
       "      <td id=\"T_66140_row4_col2\" class=\"data row4 col2\" >produce the answer. We know that Oliver Cookson is a UK entrepreneur who established the sports nutrition business Myprotein. We also know that in 2011,...</td>\n",
       "      <td id=\"T_66140_row4_col3\" class=\"data row4 col3\" >Cheshire</td>\n",
       "      <td id=\"T_66140_row4_col4\" class=\"data row4 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66140_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_66140_row5_col0\" class=\"data row5 col0\" >Find the birth date of the actor who played roles in First Wives Club and Searching for the Elephant.</td>\n",
       "      <td id=\"T_66140_row5_col1\" class=\"data row5 col1\" >February 13, 1980</td>\n",
       "      <td id=\"T_66140_row5_col2\" class=\"data row5 col2\" >find the birth date of the actor. We will first need to identify the actor's name, which is Jo Dong-hyuk. Then, we will need to...</td>\n",
       "      <td id=\"T_66140_row5_col3\" class=\"data row5 col3\" >December 11, 1977</td>\n",
       "      <td id=\"T_66140_row5_col4\" class=\"data row5 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66140_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_66140_row6_col0\" class=\"data row6 col0\" >Kyle Moran was born in the town on what river?</td>\n",
       "      <td id=\"T_66140_row6_col1\" class=\"data row6 col1\" >Castletown River</td>\n",
       "      <td id=\"T_66140_row6_col2\" class=\"data row6 col2\" >produce the answer. We know that Kyle Moran was born in Dundalk, Ireland and that there are three different pieces of information about people named...</td>\n",
       "      <td id=\"T_66140_row6_col3\" class=\"data row6 col3\" >The town of Dundalk is located near the Moran River.</td>\n",
       "      <td id=\"T_66140_row6_col4\" class=\"data row6 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66140_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_66140_row7_col0\" class=\"data row7 col0\" >The actress who played the niece in the Priest film was born in what city, country?</td>\n",
       "      <td id=\"T_66140_row7_col1\" class=\"data row7 col1\" >Surrey, England</td>\n",
       "      <td id=\"T_66140_row7_col2\" class=\"data row7 col2\" >produce the answer. We know that the actress who played the niece in the Priest film was Jackie Joseph. We also know that Jackie Joseph...</td>\n",
       "      <td id=\"T_66140_row7_col3\" class=\"data row7 col3\" >Sammie Jacqueline Joseph was born in Los Angeles, California, United States.</td>\n",
       "      <td id=\"T_66140_row7_col4\" class=\"data row7 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66140_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_66140_row8_col0\" class=\"data row8 col0\" >Name the movie in which the daughter of Noel Harrison plays Violet Trefusis.</td>\n",
       "      <td id=\"T_66140_row8_col1\" class=\"data row8 col1\" >Portrait of a Marriage</td>\n",
       "      <td id=\"T_66140_row8_col2\" class=\"data row8 col2\" >produce the answer. We know that Cathryn Harrison is the daughter of Noel Harrison, who was an actor. We also know that Violet Trefusis was...</td>\n",
       "      <td id=\"T_66140_row8_col3\" class=\"data row8 col3\" >The movie is \"The Soul's Gymnasium\".</td>\n",
       "      <td id=\"T_66140_row8_col4\" class=\"data row8 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66140_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_66140_row9_col0\" class=\"data row9 col0\" >What year was the father of the Princes in the Tower born?</td>\n",
       "      <td id=\"T_66140_row9_col1\" class=\"data row9 col1\" >1442</td>\n",
       "      <td id=\"T_66140_row9_col2\" class=\"data row9 col2\" >determine the year of birth of the father of the Princes in the Tower. We know that the Princes in the Tower were born during...</td>\n",
       "      <td id=\"T_66140_row9_col3\" class=\"data row9 col3\" >1441</td>\n",
       "      <td id=\"T_66140_row9_col4\" class=\"data row9 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66140_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_66140_row10_col0\" class=\"data row10 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
       "      <td id=\"T_66140_row10_col1\" class=\"data row10 col1\" >the River Tyne</td>\n",
       "      <td id=\"T_66140_row10_col2\" class=\"data row10 col2\" >produce the answer. We know that the Crichton Collegiate Church is situated about 0.6 mi south west of the hamlet of Crichton in Midlothian, Scotland....</td>\n",
       "      <td id=\"T_66140_row10_col3\" class=\"data row10 col3\" >The River Tyne.</td>\n",
       "      <td id=\"T_66140_row10_col4\" class=\"data row10 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66140_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_66140_row11_col0\" class=\"data row11 col0\" >Who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000?</td>\n",
       "      <td id=\"T_66140_row11_col1\" class=\"data row11 col1\" >Renault</td>\n",
       "      <td id=\"T_66140_row11_col2\" class=\"data row11 col2\" >produce the answer. We know that Michael Schumacher raced for the Benetton team in the 1995 Monaco Grand Prix. We also know that in 2000,...</td>\n",
       "      <td id=\"T_66140_row11_col3\" class=\"data row11 col3\" >Renault</td>\n",
       "      <td id=\"T_66140_row11_col4\" class=\"data row11 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66140_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_66140_row12_col0\" class=\"data row12 col0\" >André Zucca was a French photographer who worked with a German propaganda magazine published by what Nazi organization?</td>\n",
       "      <td id=\"T_66140_row12_col1\" class=\"data row12 col1\" >the Wehrmacht</td>\n",
       "      <td id=\"T_66140_row12_col2\" class=\"data row12 col2\" >produce the answer. We know that André Zucca was a French photographer who worked with a German propaganda magazine. We also know that this magazine...</td>\n",
       "      <td id=\"T_66140_row12_col3\" class=\"data row12 col3\" >The Nazi organization that published the German propaganda magazine \"Signal\" was the Schutzstaffel (SS).</td>\n",
       "      <td id=\"T_66140_row12_col4\" class=\"data row12 col4\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1272f5210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "38.46"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_hotpot(rag_compiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0ba484c-9156-47b8-8495-5ee952b66258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `context`, `question`, produce the fields `answer`.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who produced the album that included a re-recording of \"Lithium\"?\n",
      "Answer: Butch Vig\n",
      "\n",
      "Question: In what year was the star of To Hell and Back born?\n",
      "Answer: 1925\n",
      "\n",
      "Question: Which award did the first book of Gary Zukav receive?\n",
      "Answer: U.S. National Book Award\n",
      "\n",
      "Question: Which author is English: John Braine or Studs Terkel?\n",
      "Answer: John Braine\n",
      "\n",
      "Question: What documentary about the Gilgo Beach Killer debuted on A&E?\n",
      "Answer: The Killing Season\n",
      "\n",
      "Question: Who was the director of the 2009 movie featuring Peter Outerbridge as William Easton?\n",
      "Answer: Kevin Greutert\n",
      "\n",
      "Question: The heir to the Du Pont family fortune sponsored what wrestling team?\n",
      "Answer: Foxcatcher\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: ${context}\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «San Diego mayoral election, 1971 | The 1971 San Diego mayoral election was held on November 2, 1971 to elect the mayor for San Diego. Incumbent Frank Curran stood for reelection for a third term. California State Assembly member Pete Wilson and former San Diego City Attorney Ed Butler received the most votes in the primary and advanced to the runoff. Wilson was then elected mayor with a majority of the votes.»\n",
      "[2] «San Francisco mayoral election, 1975 | The 1975 mayoral election was held to select the 37th mayor of San Francisco, and was held in two parts. In the November regular election, then-Speaker of the California State Assembly George Moscone placed first with conservative city supervisor John Barbagelata second and moderate supervisor Dianne Feinstein coming in third. Moscone and Barbagelata thus both advanced to the mandated runoff election in December where Moscone narrowly defeated the conservative supervisor by 4,400 votes, a margin of less than 1%.»\n",
      "[3] «San Francisco mayoral election, 1995 | The 1995 San Francisco mayoral election was held on November 7, 1995, with a runoff election held on December 12, 1995. Former Speaker of the California State Assembly Willie Brown defeated incumbent mayor Frank Jordan in a runoff election to become the 41st Mayor of San Francisco.»\n",
      "\n",
      "Question: What year was the party of the winner of the 1971 San Francisco mayoral election founded?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m find the year the party of the winner of the 1971 San Francisco mayoral election was founded. We know that the winner of the election was Pete Wilson, who was a member of the California State Assembly. We also know that the California State Assembly was founded in 1849. Therefore, we can conclude that the party of the winner of the 1971 San Francisco mayoral election was founded in 1849.\n",
      "\n",
      "Answer: 1849\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_compiled(\"What year was the party of the winner of the 1971 San Francisco mayoral election founded?\")\n",
    "turbo.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70eb139-2b19-4da8-a024-3cc13a5b70f8",
   "metadata": {},
   "source": [
    "# Multi-Hop Retrieval and Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50dc336a-9e0e-4d40-8e89-6e5e1ccb1068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.utils.utils import deduplicate\n",
    "\n",
    "class MultiHop(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_query = dspy.ChainOfThought(\"question -> search_query\")\n",
    "\n",
    "        self.generate_query_from_context = dspy.ChainOfThought(\"context, question -> search_query\")\n",
    "\n",
    "        self.generate_answer = dspy.ChainOfThought(\"context, question -> answer\")\n",
    "    \n",
    "    def forward(self, question):\n",
    "        passages = []\n",
    "        \n",
    "        search_query = self.generate_query(question=question).search_query\n",
    "        passages += self.retrieve(search_query).passages\n",
    "\n",
    "        search_query2 = self.generate_query_from_context(context=deduplicate(passages), question=question).search_query\n",
    "\n",
    "        # TODO: Replace `None` with a call to self.retrieve to retrieve passages. Append them to the list `passages`.\n",
    "        passages += self.retrieve(search_query2).passages\n",
    "\n",
    "        return self.generate_answer(context=deduplicate(passages), question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "938d242c-027b-427b-9c47-340e69a58cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 13  (30.8): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:03<00:00,  3.25it/s]\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 13  (30.8%)\n",
      "Score: 30.77 for set: [0, 0, 0]\n",
      "New best score: 30.77 for seed -3\n",
      "Scores so far: [30.77]\n",
      "Best score: 30.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 13  (53.8): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:01<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 13  (53.8%)\n",
      "Score: 53.85 for set: [7, 7, 7]\n",
      "New best score: 53.85 for seed -2\n",
      "Scores so far: [30.77, 53.85]\n",
      "Best score: 53.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████████████████████████▋                                                                                  | 3/7 [00:08<00:11,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 13  (53.8): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:05<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 13  (53.8%)\n",
      "Score: 53.85 for set: [7, 7, 7]\n",
      "Scores so far: [30.77, 53.85, 53.85]\n",
      "Best score: 53.85\n",
      "Average of max per entry across top 1 scores: 0.5384615384615384\n",
      "Average of max per entry across top 2 scores: 0.8461538461538461\n",
      "Average of max per entry across top 3 scores: 1.0\n",
      "Average of max per entry across top 5 scores: 1.0\n",
      "Average of max per entry across top 8 scores: 1.0\n",
      "Average of max per entry across top 9999 scores: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████████████████████████████████████▎                                                             | 4/7 [00:07<00:05,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                       | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0):   8%|████████▌                                                                                                      | 1/13 [00:04<00:50,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 2  (100.0):  15%|█████████████████                                                                                              | 2/13 [00:06<00:37,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 3  (100.0):  23%|█████████████████████████▌                                                                                     | 3/13 [00:08<00:26,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 4  (100.0):  31%|██████████████████████████████████▏                                                                            | 4/13 [00:10<00:19,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 5  (80.0):  38%|███████████████████████████████████████████                                                                     | 5/13 [00:12<00:16,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 6  (83.3):  46%|███████████████████████████████████████████████████▋                                                            | 6/13 [00:13<00:12,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 7  (71.4):  54%|████████████████████████████████████████████████████████████▎                                                   | 7/13 [00:14<00:09,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.4 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 8  (75.0):  62%|████████████████████████████████████████████████████████████████████▉                                           | 8/13 [00:16<00:08,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.9 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.4 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 9  (66.7):  69%|█████████████████████████████████████████████████████████████████████████████▌                                  | 9/13 [00:18<00:06,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.2 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 13  (53.8): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:24<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 13  (53.8%)\n",
      "Score: 53.85 for set: [7, 7, 7]\n",
      "Scores so far: [30.77, 53.85, 53.85, 53.85]\n",
      "Best score: 53.85\n",
      "Average of max per entry across top 1 scores: 0.5384615384615384\n",
      "Average of max per entry across top 2 scores: 0.8461538461538461\n",
      "Average of max per entry across top 3 scores: 1.0\n",
      "Average of max per entry across top 5 scores: 1.0\n",
      "Average of max per entry across top 8 scores: 1.0\n",
      "Average of max per entry across top 9999 scores: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████▌                                                                                                                           | 1/7 [00:02<00:17,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                       | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 2  (50.0):  15%|█████████████████▏                                                                                              | 2/13 [00:03<00:15,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 3  (66.7):  23%|█████████████████████████▊                                                                                      | 3/13 [00:06<00:20,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 4  (75.0):  31%|██████████████████████████████████▍                                                                             | 4/13 [00:07<00:16,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 4.7 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 5  (60.0):  38%|███████████████████████████████████████████                                                                     | 5/13 [00:10<00:18,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.3 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 8.0 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 6  (66.7):  46%|███████████████████████████████████████████████████▋                                                            | 6/13 [00:12<00:15,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 7  (57.1):  54%|████████████████████████████████████████████████████████████▎                                                   | 7/13 [00:14<00:12,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 8  (50.0):  62%|████████████████████████████████████████████████████████████████████▉                                           | 8/13 [00:15<00:08,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 15.4 seconds after 5 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 6.3 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 13  (46.2): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:34<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 13  (46.2%)\n",
      "Score: 46.15 for set: [7, 7, 7]\n",
      "Scores so far: [30.77, 53.85, 53.85, 53.85, 46.15]\n",
      "Best score: 53.85\n",
      "Average of max per entry across top 1 scores: 0.5384615384615384\n",
      "Average of max per entry across top 2 scores: 0.8461538461538461\n",
      "Average of max per entry across top 3 scores: 1.0\n",
      "Average of max per entry across top 5 scores: 1.0\n",
      "Average of max per entry across top 8 scores: 1.0\n",
      "Average of max per entry across top 9999 scores: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████▌                                                                                                                           | 1/7 [00:01<00:06,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                       | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 2  (100.0):  15%|█████████████████                                                                                              | 2/13 [00:03<00:17,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 3  (100.0):  23%|█████████████████████████▌                                                                                     | 3/13 [00:06<00:19,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 4  (75.0):  31%|██████████████████████████████████▍                                                                             | 4/13 [00:06<00:13,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 5  (80.0):  38%|███████████████████████████████████████████                                                                     | 5/13 [00:07<00:10,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 6  (66.7):  46%|███████████████████████████████████████████████████▋                                                            | 6/13 [00:09<00:10,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 7  (71.4):  54%|████████████████████████████████████████████████████████████▎                                                   | 7/13 [00:10<00:08,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 8  (75.0):  62%|████████████████████████████████████████████████████████████████████▉                                           | 8/13 [00:12<00:06,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 9  (66.7):  69%|█████████████████████████████████████████████████████████████████████████████▌                                  | 9/13 [00:13<00:05,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 7.3 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 13  (61.5): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:21<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 13  (61.5%)\n",
      "Score: 61.54 for set: [7, 7, 7]\n",
      "New best score: 61.54 for seed 2\n",
      "Scores so far: [30.77, 53.85, 53.85, 53.85, 46.15, 61.54]\n",
      "Best score: 61.54\n",
      "Average of max per entry across top 1 scores: 0.6153846153846154\n",
      "Average of max per entry across top 2 scores: 0.8461538461538461\n",
      "Average of max per entry across top 3 scores: 1.0\n",
      "Average of max per entry across top 5 scores: 1.0\n",
      "Average of max per entry across top 8 scores: 1.0\n",
      "Average of max per entry across top 9999 scores: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████▌                                                                                                                           | 1/7 [00:01<00:07,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                       | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0):   8%|████████▋                                                                                                        | 1/13 [00:02<00:31,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 2  (0.0):  15%|█████████████████▍                                                                                               | 2/13 [00:03<00:15,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 3  (0.0):  23%|██████████████████████████                                                                                       | 3/13 [00:05<00:19,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 4  (0.0):  31%|██████████████████████████████████▊                                                                              | 4/13 [00:07<00:16,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 6  (33.3):  46%|███████████████████████████████████████████████████▋                                                            | 6/13 [00:09<00:09,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 7  (42.9):  54%|████████████████████████████████████████████████████████████▎                                                   | 7/13 [00:10<00:07,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.3 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.5 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 6.2 seconds after 5 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 13  (46.2): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 13  (46.2%)\n",
      "Score: 46.15 for set: [7, 7, 7]\n",
      "Scores so far: [30.77, 53.85, 53.85, 53.85, 46.15, 61.54, 46.15]\n",
      "Best score: 61.54\n",
      "Average of max per entry across top 1 scores: 0.6153846153846154\n",
      "Average of max per entry across top 2 scores: 0.8461538461538461\n",
      "Average of max per entry across top 3 scores: 1.0\n",
      "Average of max per entry across top 5 scores: 1.0\n",
      "Average of max per entry across top 8 scores: 1.0\n",
      "Average of max per entry across top 9999 scores: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████▌                                                                                                                           | 1/7 [00:02<00:14,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                       | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0):   8%|████████▌                                                                                                      | 1/13 [00:04<00:53,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 2  (100.0):  15%|█████████████████                                                                                              | 2/13 [00:05<00:27,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 4  (50.0):  31%|██████████████████████████████████▍                                                                             | 4/13 [00:07<00:12,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 5  (40.0):  38%|███████████████████████████████████████████                                                                     | 5/13 [00:09<00:12,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 4.6 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 3.6 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 6  (50.0):  46%|███████████████████████████████████████████████████▋                                                            | 6/13 [00:12<00:16,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.5 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 7  (42.9):  54%|████████████████████████████████████████████████████████████▎                                                   | 7/13 [00:13<00:10,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.4 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 8  (50.0):  62%|████████████████████████████████████████████████████████████████████▉                                           | 8/13 [00:14<00:07,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.3 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 13  (46.2): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:21<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 13  (46.2%)\n",
      "Score: 46.15 for set: [7, 7, 7]\n",
      "Scores so far: [30.77, 53.85, 53.85, 53.85, 46.15, 61.54, 46.15, 46.15]\n",
      "Best score: 61.54\n",
      "Average of max per entry across top 1 scores: 0.6153846153846154\n",
      "Average of max per entry across top 2 scores: 0.8461538461538461\n",
      "Average of max per entry across top 3 scores: 1.0\n",
      "Average of max per entry across top 5 scores: 1.0\n",
      "Average of max per entry across top 8 scores: 1.0\n",
      "Average of max per entry across top 9999 scores: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████████████████████████████████████▎                                                             | 4/7 [00:07<00:05,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                       | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0):   8%|████████▌                                                                                                      | 1/13 [00:04<00:50,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 2  (100.0):  15%|█████████████████                                                                                              | 2/13 [00:05<00:27,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 3  (66.7):  23%|█████████████████████████▊                                                                                      | 3/13 [00:06<00:19,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 4  (75.0):  31%|██████████████████████████████████▍                                                                             | 4/13 [00:10<00:23,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 6.1 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 5  (80.0):  38%|███████████████████████████████████████████                                                                     | 5/13 [00:12<00:18,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 4.7 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 6  (66.7):  46%|███████████████████████████████████████████████████▋                                                            | 6/13 [00:14<00:16,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.5 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 7  (57.1):  54%|████████████████████████████████████████████████████████████▎                                                   | 7/13 [00:15<00:11,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.1 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 5.6 seconds after 5 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 8  (62.5):  62%|████████████████████████████████████████████████████████████████████▉                                           | 8/13 [00:18<00:11,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 8.9 seconds after 5 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 10  (70.0):  77%|████████████████████████████████████████████████████████████████████████████████████▌                         | 10/13 [00:25<00:08,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 21.4 seconds after 6 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 13  (61.5): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:50<00:00,  3.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 13  (61.5%)\n",
      "Score: 61.54 for set: [7, 7, 7]\n",
      "Scores so far: [30.77, 53.85, 53.85, 53.85, 46.15, 61.54, 46.15, 46.15, 61.54]\n",
      "Best score: 61.54\n",
      "Average of max per entry across top 1 scores: 0.6153846153846154\n",
      "Average of max per entry across top 2 scores: 0.9230769230769231\n",
      "Average of max per entry across top 3 scores: 1.0\n",
      "Average of max per entry across top 5 scores: 1.0\n",
      "Average of max per entry across top 8 scores: 1.0\n",
      "Average of max per entry across top 9999 scores: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████▌                                                                                                                           | 1/7 [00:01<00:06,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9 / 13  (69.2): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:01<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9 / 13  (69.2%)\n",
      "Score: 69.23 for set: [7, 7, 7]\n",
      "New best score: 69.23 for seed 6\n",
      "Scores so far: [30.77, 53.85, 53.85, 53.85, 46.15, 61.54, 46.15, 46.15, 61.54, 69.23]\n",
      "Best score: 69.23\n",
      "Average of max per entry across top 1 scores: 0.6923076923076923\n",
      "Average of max per entry across top 2 scores: 0.9230769230769231\n",
      "Average of max per entry across top 3 scores: 1.0\n",
      "Average of max per entry across top 5 scores: 1.0\n",
      "Average of max per entry across top 8 scores: 1.0\n",
      "Average of max per entry across top 9999 scores: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████████████████████████▋                                                                                  | 3/7 [00:04<00:05,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                       | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0):   8%|████████▌                                                                                                      | 1/13 [00:04<00:53,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 2  (100.0):  15%|█████████████████                                                                                              | 2/13 [00:05<00:28,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 3  (66.7):  23%|█████████████████████████▊                                                                                      | 3/13 [00:06<00:17,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 4  (50.0):  31%|██████████████████████████████████▍                                                                             | 4/13 [00:08<00:18,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 5  (60.0):  38%|███████████████████████████████████████████                                                                     | 5/13 [00:09<00:13,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 7.9 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.9 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 6  (66.7):  46%|███████████████████████████████████████████████████▋                                                            | 6/13 [00:15<00:20,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 7  (57.1):  54%|████████████████████████████████████████████████████████████▎                                                   | 7/13 [00:16<00:13,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 9.2 seconds after 5 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 5.1 seconds after 4 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 8  (50.0):  62%|████████████████████████████████████████████████████████████████████▉                                           | 8/13 [00:20<00:14,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 9  (44.4):  69%|█████████████████████████████████████████████████████████████████████████████▌                                  | 9/13 [00:21<00:09,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 5 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 10  (40.0):  77%|████████████████████████████████████████████████████████████████████████████████████▌                         | 10/13 [00:25<00:08,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n",
      "Backing off 19.3 seconds after 6 tries calling function <function GPT3.request at 0x1129777e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 13  (46.2): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:48<00:00,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 13  (46.2%)\n",
      "Score: 46.15 for set: [7, 7, 7]\n",
      "Scores so far: [30.77, 53.85, 53.85, 53.85, 46.15, 61.54, 46.15, 46.15, 61.54, 69.23, 46.15]\n",
      "Best score: 69.23\n",
      "Average of max per entry across top 1 scores: 0.6923076923076923\n",
      "Average of max per entry across top 2 scores: 0.9230769230769231\n",
      "Average of max per entry across top 3 scores: 1.0\n",
      "Average of max per entry across top 5 scores: 1.0\n",
      "Average of max per entry across top 8 scores: 1.0\n",
      "Average of max per entry across top 9999 scores: 1.0\n",
      "11 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "multihop_compiled = optimizer2.compile(MultiHop(), trainset=train, valset=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f642ee3-bd96-4f0f-9570-1cd4ac8f2243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9 / 13  (69.2): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 2084.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9 / 13  (69.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:263: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['✔️ [True]' 'False' 'False' '✔️ [True]' '✔️ [True]' 'False' '✔️ [True]'\n",
      " 'False' '✔️ [True]' '✔️ [True]' '✔️ [True]' '✔️ [True]' '✔️ [True]']' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_402a7 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_402a7 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_402a7_row0_col0, #T_402a7_row0_col1, #T_402a7_row0_col2, #T_402a7_row0_col3, #T_402a7_row0_col4, #T_402a7_row1_col0, #T_402a7_row1_col1, #T_402a7_row1_col2, #T_402a7_row1_col3, #T_402a7_row1_col4, #T_402a7_row2_col0, #T_402a7_row2_col1, #T_402a7_row2_col2, #T_402a7_row2_col3, #T_402a7_row2_col4, #T_402a7_row3_col0, #T_402a7_row3_col1, #T_402a7_row3_col2, #T_402a7_row3_col3, #T_402a7_row3_col4, #T_402a7_row4_col0, #T_402a7_row4_col1, #T_402a7_row4_col2, #T_402a7_row4_col3, #T_402a7_row4_col4, #T_402a7_row5_col0, #T_402a7_row5_col1, #T_402a7_row5_col2, #T_402a7_row5_col3, #T_402a7_row5_col4, #T_402a7_row6_col0, #T_402a7_row6_col1, #T_402a7_row6_col2, #T_402a7_row6_col3, #T_402a7_row6_col4, #T_402a7_row7_col0, #T_402a7_row7_col1, #T_402a7_row7_col2, #T_402a7_row7_col3, #T_402a7_row7_col4, #T_402a7_row8_col0, #T_402a7_row8_col1, #T_402a7_row8_col2, #T_402a7_row8_col3, #T_402a7_row8_col4, #T_402a7_row9_col0, #T_402a7_row9_col1, #T_402a7_row9_col2, #T_402a7_row9_col3, #T_402a7_row9_col4, #T_402a7_row10_col0, #T_402a7_row10_col1, #T_402a7_row10_col2, #T_402a7_row10_col3, #T_402a7_row10_col4, #T_402a7_row11_col0, #T_402a7_row11_col1, #T_402a7_row11_col2, #T_402a7_row11_col3, #T_402a7_row11_col4, #T_402a7_row12_col0, #T_402a7_row12_col1, #T_402a7_row12_col2, #T_402a7_row12_col3, #T_402a7_row12_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_402a7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_402a7_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_402a7_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_402a7_level0_col2\" class=\"col_heading level0 col2\" >rationale</th>\n",
       "      <th id=\"T_402a7_level0_col3\" class=\"col_heading level0 col3\" >pred_answer</th>\n",
       "      <th id=\"T_402a7_level0_col4\" class=\"col_heading level0 col4\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_402a7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_402a7_row0_col0\" class=\"data row0 col0\" >Who has a broader scope of profession: E. L. Doctorow or Julia Peterkin?</td>\n",
       "      <td id=\"T_402a7_row0_col1\" class=\"data row0 col1\" >E. L. Doctorow</td>\n",
       "      <td id=\"T_402a7_row0_col2\" class=\"data row0 col2\" >determine who has a broader scope of profession. We know that E. L. Doctorow is an American novelist, editor, and professor, while Julia Peterkin is...</td>\n",
       "      <td id=\"T_402a7_row0_col3\" class=\"data row0 col3\" >E. L. Doctorow</td>\n",
       "      <td id=\"T_402a7_row0_col4\" class=\"data row0 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_402a7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_402a7_row1_col0\" class=\"data row1 col0\" >Right Back At It Again contains lyrics co-written by the singer born in what city?</td>\n",
       "      <td id=\"T_402a7_row1_col1\" class=\"data row1 col1\" >Gainesville, Florida</td>\n",
       "      <td id=\"T_402a7_row1_col2\" class=\"data row1 col2\" >find the city where the singer was born. We know that the song \"Right Back At It Again\" is by A Day to Remember, and...</td>\n",
       "      <td id=\"T_402a7_row1_col3\" class=\"data row1 col3\" >Belleville</td>\n",
       "      <td id=\"T_402a7_row1_col4\" class=\"data row1 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_402a7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_402a7_row2_col0\" class=\"data row2 col0\" >What year was the party of the winner of the 1971 San Francisco mayoral election founded?</td>\n",
       "      <td id=\"T_402a7_row2_col1\" class=\"data row2 col1\" >1828</td>\n",
       "      <td id=\"T_402a7_row2_col2\" class=\"data row2 col2\" >find the year the party was founded. We know that the winner of the 1971 San Francisco mayoral election was Pete Wilson, and we know...</td>\n",
       "      <td id=\"T_402a7_row2_col3\" class=\"data row2 col3\" >1998</td>\n",
       "      <td id=\"T_402a7_row2_col4\" class=\"data row2 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_402a7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_402a7_row3_col0\" class=\"data row3 col0\" >Anthony Dirrell is the brother of which super middleweight title holder?</td>\n",
       "      <td id=\"T_402a7_row3_col1\" class=\"data row3 col1\" >Andre Dirrell</td>\n",
       "      <td id=\"T_402a7_row3_col2\" class=\"data row3 col2\" >find the name of the super middleweight title holder. We know that Anthony Dirrell is the younger brother of Andre Dirrell, who is also a...</td>\n",
       "      <td id=\"T_402a7_row3_col3\" class=\"data row3 col3\" >Andre Dirrell</td>\n",
       "      <td id=\"T_402a7_row3_col4\" class=\"data row3 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_402a7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_402a7_row4_col0\" class=\"data row4 col0\" >The sports nutrition business established by Oliver Cookson is based in which county in the UK?</td>\n",
       "      <td id=\"T_402a7_row4_col1\" class=\"data row4 col1\" >Cheshire</td>\n",
       "      <td id=\"T_402a7_row4_col2\" class=\"data row4 col2\" >find the county where the sports nutrition business is based. We know that the business is called Myprotein and that it was established by Oliver...</td>\n",
       "      <td id=\"T_402a7_row4_col3\" class=\"data row4 col3\" >Cheshire</td>\n",
       "      <td id=\"T_402a7_row4_col4\" class=\"data row4 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_402a7_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_402a7_row5_col0\" class=\"data row5 col0\" >Find the birth date of the actor who played roles in First Wives Club and Searching for the Elephant.</td>\n",
       "      <td id=\"T_402a7_row5_col1\" class=\"data row5 col1\" >February 13, 1980</td>\n",
       "      <td id=\"T_402a7_row5_col2\" class=\"data row5 col2\" >find the birth date. We know that the actor played roles in First Wives Club and Searching for the Elephant, and we know that her...</td>\n",
       "      <td id=\"T_402a7_row5_col3\" class=\"data row5 col3\" >January 14, 1971</td>\n",
       "      <td id=\"T_402a7_row5_col4\" class=\"data row5 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_402a7_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_402a7_row6_col0\" class=\"data row6 col0\" >Kyle Moran was born in the town on what river?</td>\n",
       "      <td id=\"T_402a7_row6_col1\" class=\"data row6 col1\" >Castletown River</td>\n",
       "      <td id=\"T_402a7_row6_col2\" class=\"data row6 col2\" >find the town where Kyle Moran was born. We know that Kyle Moran is an Irish footballer, and we know that he was born on...</td>\n",
       "      <td id=\"T_402a7_row6_col3\" class=\"data row6 col3\" >Castletown River</td>\n",
       "      <td id=\"T_402a7_row6_col4\" class=\"data row6 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_402a7_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_402a7_row7_col0\" class=\"data row7 col0\" >The actress who played the niece in the Priest film was born in what city, country?</td>\n",
       "      <td id=\"T_402a7_row7_col1\" class=\"data row7 col1\" >Surrey, England</td>\n",
       "      <td id=\"T_402a7_row7_col2\" class=\"data row7 col2\" >find the city and country of birth. We know that the actress is Francesca Cardinale, and we know that she is the niece of Claudia...</td>\n",
       "      <td id=\"T_402a7_row7_col3\" class=\"data row7 col3\" >Buenos Aires, Argentina</td>\n",
       "      <td id=\"T_402a7_row7_col4\" class=\"data row7 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_402a7_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_402a7_row8_col0\" class=\"data row8 col0\" >Name the movie in which the daughter of Noel Harrison plays Violet Trefusis.</td>\n",
       "      <td id=\"T_402a7_row8_col1\" class=\"data row8 col1\" >Portrait of a Marriage</td>\n",
       "      <td id=\"T_402a7_row8_col2\" class=\"data row8 col2\" >find the movie. We know that the daughter of Noel Harrison is Cathryn Harrison, and we know that she played Violet Trefusis. We also know...</td>\n",
       "      <td id=\"T_402a7_row8_col3\" class=\"data row8 col3\" >Portrait of a Marriage</td>\n",
       "      <td id=\"T_402a7_row8_col4\" class=\"data row8 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_402a7_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_402a7_row9_col0\" class=\"data row9 col0\" >What year was the father of the Princes in the Tower born?</td>\n",
       "      <td id=\"T_402a7_row9_col1\" class=\"data row9 col1\" >1442</td>\n",
       "      <td id=\"T_402a7_row9_col2\" class=\"data row9 col2\" >find the year of birth. We know that the father of the Princes in the Tower is Edward IV, and we know that he died...</td>\n",
       "      <td id=\"T_402a7_row9_col3\" class=\"data row9 col3\" >1442</td>\n",
       "      <td id=\"T_402a7_row9_col4\" class=\"data row9 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_402a7_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_402a7_row10_col0\" class=\"data row10 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
       "      <td id=\"T_402a7_row10_col1\" class=\"data row10 col1\" >the River Tyne</td>\n",
       "      <td id=\"T_402a7_row10_col2\" class=\"data row10 col2\" >find the river near the Crichton Collegiate Church. We know that the church is situated near the village of Crichton, which is located in Midlothian,...</td>\n",
       "      <td id=\"T_402a7_row10_col3\" class=\"data row10 col3\" >River Tyne</td>\n",
       "      <td id=\"T_402a7_row10_col4\" class=\"data row10 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_402a7_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_402a7_row11_col0\" class=\"data row11 col0\" >Who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000?</td>\n",
       "      <td id=\"T_402a7_row11_col1\" class=\"data row11 col1\" >Renault</td>\n",
       "      <td id=\"T_402a7_row11_col2\" class=\"data row11 col2\" >find the answer. We know that Michael Schumacher raced for Benetton in the 1995 Monaco Grand Prix. We also know that in 2000, the team...</td>\n",
       "      <td id=\"T_402a7_row11_col3\" class=\"data row11 col3\" >Renault</td>\n",
       "      <td id=\"T_402a7_row11_col4\" class=\"data row11 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_402a7_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_402a7_row12_col0\" class=\"data row12 col0\" >André Zucca was a French photographer who worked with a German propaganda magazine published by what Nazi organization?</td>\n",
       "      <td id=\"T_402a7_row12_col1\" class=\"data row12 col1\" >the Wehrmacht</td>\n",
       "      <td id=\"T_402a7_row12_col2\" class=\"data row12 col2\" >find the Nazi organization that published the German propaganda magazine. We know that André Zucca was a French photographer and Nazi collaborator, and that he...</td>\n",
       "      <td id=\"T_402a7_row12_col3\" class=\"data row12 col3\" >Wehrmacht</td>\n",
       "      <td id=\"T_402a7_row12_col4\" class=\"data row12 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1316ecb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "69.23"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_hotpot(multihop_compiled, devset=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92869f59-9b29-451d-80a5-c33fae3791b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `question`, produce the fields `search_query`.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the search_query}. We ...\n",
      "Search Query: ${search_query}\n",
      "\n",
      "---\n",
      "\n",
      "Question: In what year was the star of To Hell and Back born?\n",
      "Reasoning: Let's think step by step in order to find the year the star of To Hell and Back was born. We need to know the name of the star, then we can search for their birth year.\n",
      "Search Query: To Hell and Back star birth year\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m find out who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000. We need to know the name of the team, then we can search for who purchased it in 2000.\n",
      "Search Query: 1995 Monaco Grand Prix team purchase 2000\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `context`, `question`, produce the fields `search_query`.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: ${context}\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the search_query}. We ...\n",
      "\n",
      "Search Query: ${search_query}\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «To Hell and Back (film) | To Hell and Back is a Technicolor and CinemaScope war film released in 1955. It was directed by Jesse Hibbs and starred Audie Murphy as himself. It is based on the 1949 autobiography of the same name and is an account of Murphy's World War II experiences as a soldier in the U.S. Army. The book was ghostwritten by his friend, David \"Spec\" McClure, who served in the Army's Signal Corps during World War II.»\n",
      "[2] «Hell and Back (film) | Hell and Back is a 2015 American stop-motion adult animated fantasy comedy film directed by Tom Gianas and Ross Shuman, and written by Gianas, Hugh Sterbakov, and Zeb Wells. It stars the voices of Nick Swardson, Mila Kunis, Bob Odenkirk, T.J. Miller, Rob Riggle, Susan Sarandon, and Danny McBride. The film was released October 2, 2015, by Freestyle Releasing.»\n",
      "[3] «H.P. Lovecraft's: Necronomicon | H.P. Lovecraft's: Necronomicon, original title Necronomicon, also called Necronomicon: Book of the Dead or Necronomicon: To Hell and Back is an American anthology horror film released in 1993. It was directed by Brian Yuzna, Christophe Gans and Shusuke Kaneko and was written by Gans, Yuzna, Brent V. Friedman, and Kazunori Itō. The film stars Bruce Payne as Edward De Lapoer, Richard Lynch as Jethro De Lapoer, Jeffrey Combs as H. P. Lovecraft, Belinda Bauer as Nancy Gallmore, and David Warner as Dr. Madden.»\n",
      "[4] «List of songs written by Audie Murphy | Audie Murphy (1925–1971) was born into a poor family in Texas and became a highly decorated American soldier who served with the United States Army in nine campaigns in Europe from 1942 to 1945. He was the recipient of the Medal of Honor for his combat heroism in World War II and received every American combat award for valor available from the Army at the time of his service. At the onset of the Korean War, he was commissioned as an officer in the Texas National Guard and served with the Guard for sixteen years before retiring from military service. His home state posthumously awarded him the Texas Legislative Medal of Honor for his combined service in the Army and the Guard.»\n",
      "[5] «Audie Murphy | Audie Leon Murphy (20 June 1925 – 28 May 1971) was one of the most decorated American combat soldiers of World War II, receiving every military combat award for valor available from the U.S. Army, as well as French and Belgian awards for heroism. Murphy received the Medal of Honor for valor demonstrated at the age of 19 for single-handedly holding off an entire company of German soldiers for an hour at the Colmar Pocket in France in January 1945, then leading a successful counterattack while wounded and out of ammunition.»\n",
      "[6] «Audie Murphy honors and awards | Audie Murphy (20 June 1925 – 28 May 1971) was one of the most decorated United States Army combat soldiers of World War II, serving from 1942 to 1945. He received every American combat award for valor available at the time of his service, including the Medal of Honor. He also received recognitions from France and Belgium. With his 1945 military discharge at the end of the war, Murphy became an advocate of treatment for post-traumatic stress disorder in veterans. The Audie L. Murphy Memorial VA Hospital in San Antonio and the Sergeant Audie Murphy Clubs (SAMC) on military bases honor his contributions. He joined the Texas National Guard in 1950, transferring to reserve status in 1956 and remaining in the Guard until 1969. He also had a civilian career as a film actor and songwriter. Recognitions he received both during his lifetime and posthumously are listed below.»\n",
      "\n",
      "Question: In what year was the star of To Hell and Back born?\n",
      "\n",
      "Reasoning: Let's think step by step in order to find the year that the star of To Hell and Back, Audie Murphy, was born. We know that the film was released in 1955 and is based on Murphy's World War II experiences. We also know that Murphy was a soldier in the U.S. Army during World War II. Therefore, we can assume that he was likely born sometime in the early 1920s.\n",
      "\n",
      "Search Query: What year was Audie Murphy born?\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «2000 Monaco Grand Prix | The 2000 Monaco Grand Prix (formally the LVIII Grand Prix Automobile de Monaco) was a Formula One motor race held on 4 June 2000 at the Circuit de Monaco. It was the seventh race of the 2000 Formula One season and the 58th Monaco Grand Prix. The 78-lap race was won by McLaren driver David Coulthard after starting from third position. Rubens Barrichello finished second for the Ferrari team with Benetton driver Giancarlo Fisichella third.»\n",
      "[2] «1995 Monaco Grand Prix | The 1995 Monaco Grand Prix (formally the LIII Grand Prix de Monaco) was a Formula One motor race held on 28 May 1995 at the Circuit de Monaco, Monte Carlo, Monaco. It was the fifth round of the 1995 Formula One season. The 78-lap race was won by Michael Schumacher for the Benetton team after starting from second position. Damon Hill finished second for Williams after starting from pole position and leading the first 23 laps of the race, ahead of Gerhard Berger in a Ferrari car. The remaining points-scoring positions were filled by Johnny Herbert in the second Benetton, Mark Blundell (McLaren) and Heinz-Harald Frentzen (Sauber). Schumacher's win was his third of the season thus far and extended his lead in the World Drivers' Championship over Hill to five points. It was also Renault's first win in the Monaco Grand Prix, as Benetton's engine supplier.»\n",
      "[3] «1999 Monaco Grand Prix | The 1999 Monaco Grand Prix (formally the LVII Grand Prix Automobile de Monaco) was a Formula One motor race held on 16 May 1999 at the Circuit de Monaco in Monte Carlo, Monaco. It was the fourth race of the 1999 Formula One season. The 78-lap race was won by Ferrari driver Michael Schumacher after starting from second position. It was Schumacher's 16th win with Ferrari, breaking the record held by Niki Lauda. His team-mate Eddie Irvine finished second with Mika Häkkinen third for the McLaren team.»\n",
      "\n",
      "Question: Who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m find out who purchased the team that Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000. We know that Schumacher won the race in 1995 for the Benetton team. In 2000, he raced for the McLaren team. Therefore, we can assume that the team was purchased by McLaren between 1995 and 2000.\n",
      "\n",
      "Search Query: Who purchased the Benetton team in 2000?\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `context`, `question`, produce the fields `answer`.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who produced the album that included a re-recording of \"Lithium\"?\n",
      "Answer: Butch Vig\n",
      "\n",
      "Question: Which award did the first book of Gary Zukav receive?\n",
      "Answer: U.S. National Book Award\n",
      "\n",
      "Question: What documentary about the Gilgo Beach Killer debuted on A&E?\n",
      "Answer: The Killing Season\n",
      "\n",
      "Question: Who was the director of the 2009 movie featuring Peter Outerbridge as William Easton?\n",
      "Answer: Kevin Greutert\n",
      "\n",
      "Question: Which author is English: John Braine or Studs Terkel?\n",
      "Answer: John Braine\n",
      "\n",
      "Question: The heir to the Du Pont family fortune sponsored what wrestling team?\n",
      "Answer: Foxcatcher\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: ${context}\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «To Hell and Back (film) | To Hell and Back is a Technicolor and CinemaScope war film released in 1955. It was directed by Jesse Hibbs and starred Audie Murphy as himself. It is based on the 1949 autobiography of the same name and is an account of Murphy's World War II experiences as a soldier in the U.S. Army. The book was ghostwritten by his friend, David \"Spec\" McClure, who served in the Army's Signal Corps during World War II.»\n",
      "[2] «Hell and Back (film) | Hell and Back is a 2015 American stop-motion adult animated fantasy comedy film directed by Tom Gianas and Ross Shuman, and written by Gianas, Hugh Sterbakov, and Zeb Wells. It stars the voices of Nick Swardson, Mila Kunis, Bob Odenkirk, T.J. Miller, Rob Riggle, Susan Sarandon, and Danny McBride. The film was released October 2, 2015, by Freestyle Releasing.»\n",
      "[3] «H.P. Lovecraft's: Necronomicon | H.P. Lovecraft's: Necronomicon, original title Necronomicon, also called Necronomicon: Book of the Dead or Necronomicon: To Hell and Back is an American anthology horror film released in 1993. It was directed by Brian Yuzna, Christophe Gans and Shusuke Kaneko and was written by Gans, Yuzna, Brent V. Friedman, and Kazunori Itō. The film stars Bruce Payne as Edward De Lapoer, Richard Lynch as Jethro De Lapoer, Jeffrey Combs as H. P. Lovecraft, Belinda Bauer as Nancy Gallmore, and David Warner as Dr. Madden.»\n",
      "[4] «List of songs written by Audie Murphy | Audie Murphy (1925–1971) was born into a poor family in Texas and became a highly decorated American soldier who served with the United States Army in nine campaigns in Europe from 1942 to 1945. He was the recipient of the Medal of Honor for his combat heroism in World War II and received every American combat award for valor available from the Army at the time of his service. At the onset of the Korean War, he was commissioned as an officer in the Texas National Guard and served with the Guard for sixteen years before retiring from military service. His home state posthumously awarded him the Texas Legislative Medal of Honor for his combined service in the Army and the Guard.»\n",
      "[5] «Audie Murphy | Audie Leon Murphy (20 June 1925 – 28 May 1971) was one of the most decorated American combat soldiers of World War II, receiving every military combat award for valor available from the U.S. Army, as well as French and Belgian awards for heroism. Murphy received the Medal of Honor for valor demonstrated at the age of 19 for single-handedly holding off an entire company of German soldiers for an hour at the Colmar Pocket in France in January 1945, then leading a successful counterattack while wounded and out of ammunition.»\n",
      "[6] «Audie Murphy honors and awards | Audie Murphy (20 June 1925 – 28 May 1971) was one of the most decorated United States Army combat soldiers of World War II, serving from 1942 to 1945. He received every American combat award for valor available at the time of his service, including the Medal of Honor. He also received recognitions from France and Belgium. With his 1945 military discharge at the end of the war, Murphy became an advocate of treatment for post-traumatic stress disorder in veterans. The Audie L. Murphy Memorial VA Hospital in San Antonio and the Sergeant Audie Murphy Clubs (SAMC) on military bases honor his contributions. He joined the Texas National Guard in 1950, transferring to reserve status in 1956 and remaining in the Guard until 1969. He also had a civilian career as a film actor and songwriter. Recognitions he received both during his lifetime and posthumously are listed below.»\n",
      "\n",
      "Question: In what year was the star of To Hell and Back born?\n",
      "\n",
      "Reasoning: Let's think step by step in order to find the year of birth. We know that the star of To Hell and Back is Audie Murphy, and we know that he was born on June 20th. We also know that he served in World War II, which took place from 1939 to 1945. We can use this information to calculate the year of his birth.\n",
      "\n",
      "Answer: 1925\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «2000 Monaco Grand Prix | The 2000 Monaco Grand Prix (formally the LVIII Grand Prix Automobile de Monaco) was a Formula One motor race held on 4 June 2000 at the Circuit de Monaco. It was the seventh race of the 2000 Formula One season and the 58th Monaco Grand Prix. The 78-lap race was won by McLaren driver David Coulthard after starting from third position. Rubens Barrichello finished second for the Ferrari team with Benetton driver Giancarlo Fisichella third.»\n",
      "[2] «1995 Monaco Grand Prix | The 1995 Monaco Grand Prix (formally the LIII Grand Prix de Monaco) was a Formula One motor race held on 28 May 1995 at the Circuit de Monaco, Monte Carlo, Monaco. It was the fifth round of the 1995 Formula One season. The 78-lap race was won by Michael Schumacher for the Benetton team after starting from second position. Damon Hill finished second for Williams after starting from pole position and leading the first 23 laps of the race, ahead of Gerhard Berger in a Ferrari car. The remaining points-scoring positions were filled by Johnny Herbert in the second Benetton, Mark Blundell (McLaren) and Heinz-Harald Frentzen (Sauber). Schumacher's win was his third of the season thus far and extended his lead in the World Drivers' Championship over Hill to five points. It was also Renault's first win in the Monaco Grand Prix, as Benetton's engine supplier.»\n",
      "[3] «1999 Monaco Grand Prix | The 1999 Monaco Grand Prix (formally the LVII Grand Prix Automobile de Monaco) was a Formula One motor race held on 16 May 1999 at the Circuit de Monaco in Monte Carlo, Monaco. It was the fourth race of the 1999 Formula One season. The 78-lap race was won by Ferrari driver Michael Schumacher after starting from second position. It was Schumacher's 16th win with Ferrari, breaking the record held by Niki Lauda. His team-mate Eddie Irvine finished second with Mika Häkkinen third for the McLaren team.»\n",
      "[4] «Benetton Formula | Benetton Formula Ltd., commonly referred to simply as Benetton, was a Formula One constructor that participated from to . The team was owned by the Benetton family who run a worldwide chain of clothing stores of the same name. In 2000 the team was purchased by Renault, but competed as Benetton for the 2000 and 2001 seasons. In the team became Renault F1.»\n",
      "[5] «Benetton B200 | The Benetton B200 was the car with which the Benetton Formula One team competed in the 2000 Formula One season. It was driven by Giancarlo Fisichella and Alexander Wurz, who was dropped by the team at the end of the year after two consecutive poor seasons.»\n",
      "[6] «Benetton B186 | The Benetton B186 was the Formula One car built and raced by the Benetton team for the 1986 Formula One World Championship. It was the first car to be constructed and raced by Benetton, which had bought the Toleman team at the end of after several years of sponsoring it and other teams, including Alfa Romeo and Tyrrell.»\n",
      "\n",
      "Question: Who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m find the answer. We know that Michael Schumacher raced for Benetton in the 1995 Monaco Grand Prix. We also know that in 2000, the team was purchased by another company. We can use this information to find the answer.\n",
      "\n",
      "Answer: Renault\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multihop_compiled(question=\"Who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000?\")\n",
    "turbo.inspect_history(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a0956-ae94-4d2d-a1f5-0e8ae687641d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
